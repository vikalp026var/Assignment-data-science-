{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "54fe679f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans1: Manhattan Distance is the L1 norm form (L1 norm is the sum of the magnitude of vectors in space), while Euclidean Distance is L2 Norm form.\n",
    "# the choice between the Euclidean distance and the Manhattan distance in KNN depends on the specific characteristics of the data, including the scales of the features, relevance of features, desired decision boundary shape, and the dimensionality of the feature space.\n",
    "#It increase the time complexity of KNN classifier or regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e6906add",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans2:Choosing the optimal value of k in KNN (K-Nearest Neighbors) is crucial for achieving the best performance of the classifier or regressor. The value of k determines the number of neighbors considered for making predictions.\n",
    "#Elbow method .\n",
    "#GridSearch Cv\n",
    "#Randomised Search cv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e7327064",
   "metadata": {},
   "outputs": [],
   "source": [
    "#ANs3:The choice of distance metric in a KNN (K-Nearest Neighbors) classifier has a significant impact on its performance. The distance metric determines how the similarity or dissimilarity between data points is measured, which, in turn, affects the classification decisions made by the algorithm.\n",
    "#It is depend on the distribution of data ,the presence of outliers and the dimensionality when choosing a distance metric for a KNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3fae9526",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans4:The common hyperparameters is number of neighbours(k) it is critical hyperparameters in knn ,distance metric (common distance metrics include euclidean distance ,Mabhattan distance Minkowski distance)\n",
    "#Hyperparamter is Gridsearch cv ,crossvalidation model evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "62a3237f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#if the size of the training set increase then complexity of model is increase ,the training,Bias and Variance Trade-off: \n",
    "# The size of the training set is related to the bias-variance trade-off. A small training set can result in high variance, where the model is highly sensitive to the specific examples in the training data, leading to unstable predictions. \n",
    "#Cross validation,Learning curves,Data augmentation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e5b16559",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Ans6:It increase the complexity it is overcome by the decreasing the size of the dataset.\n",
    "#Curse of Dimensionality: KNN suffers from the curse of dimensionality, which refers to the deterioration of performance in high-dimensional spaces. As the number of features increases, the density of the data becomes sparse, and the notion of distance becomes less meaningful. Dimensionality reduction techniques, such as Principal Component Analysis (PCA) or feature selection methods, can be applied to reduce the dimensionality of the data while preserving the most informative features. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecf7cbfe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e89b2f0",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
